---
layout: post
title: "来自工业界的知识库 RAG（六），另类的 RAG 框架 dsRAG 核心亮点解读"
subtitle:   "RAG services from industry (6)，an Interpretation of the Core Highlights of the RAG Framework dsRAG"
date:       2024-08-28 09:00:00
author:     "Bryan"
header-mask: 0.3
catalog:    true
tags:
    - rag
    - agent
---

## 背景介绍
在前面介绍了较多开源 RAG 框架，比如主打 Rerank 的 [QAnything](https://zhuanlan.zhihu.com/p/697031773), 主打精细文件解析的 [RagFlow](https://zhuanlan.zhihu.com/p/697902937), 主打模块化灵活组合的 [GoMate](https://zhuanlan.zhihu.com/p/705218535)。这些库的设计除了特殊之处外，相似的部分会比较多。

最近有注意到一款有些另类的 RAG 框架 dsRAG，使用了较多新的设计，因此花了一些时间对其核心亮点进行了考察，整理相关内容在这边。

## 核心亮点
[dsRAG](https://github.com/D-Star-AI/dsRAG) 官方的介绍是一款高性能非结构化数据检索引擎，从 2024 年 4 月开源至现在，Github star 数量为 730。相对其他 RAG 项目动辄几千 star 的量级，dsRAG 属于比较冷门的了。

从实际了解的情况来看，这个现状也比较正常，dsRAG 确实不太适合用在生产环境。但是不可否认 dsRAG 的独特之处确实值得了解下：

1. 语义分块（Semantic sectioning）：相对其他框架大多采取 Level 2 级别的递归字符切片，部分实现的是 Level 3 的基于文件类型的切片方案，而 dsRAG 实现的是 Level 4 级别的语义分块，有兴趣了解切片的层级表示可以查看 [5_Levels_Of_Text_Splitting](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb) ;
2. 自动上下文（AutoContext）：这个是指在分块的内容前增加额外的上下文信息，这样可以提升单个块的内容的可检索性。目前大部分 RAG 框架都没有实现对应的能力；
3. 文本块智能组合（Relevant Segment Extraction）：为了避免分片信息不完整的问题，dsRAG 会将检索的文本块智能组合，这样在复杂问题时可以提供更完整的信息。目前大部分的 RAG 框架同样实现类似的功能；

下面就主要围绕上面提到的亮点，深入到源码层面，理解其中的技术细节。

## 功能细节

#### 语义分块

语义分块是指基于语义的相似性来文本切分，[langchain](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/semantic-chunker/) 中就实现了类似的能力，就是将原始文本切分为句子，之后比较句子向量的相似性，如果相似性超过一定的阈值，则进行切分。

dsRAG 的语义分块是基于大模型实现，主要的流程如下所示：

1. 将原始的文本按照换行符 `\n` 切分为按行的句子；
2. 利用大模型生成分片方案，考虑到大模型的语义理解能力，大模型给出的分片可能比常规的向量模型更准确；

实际实现时基于大模型的结构化输出能力，因此需要目前只支持 OpenAI 和 Anthropic 的大模型，实现就极其简单了：

```python
class Section(BaseModel):
    title: str = Field(description="main topic of this section of the document (very descriptive)")
    start_index: int = Field(description="line number where the section begins (inclusive)")
    end_index: int = Field(description="line number where the section ends (inclusive)")


class StructuredDocument(BaseModel):
    """obtains meaningful sections, each centered around a single concept/topic"""
    sections: List[Section] = Field(description="a list of sections of the document")

# 大模型输出结构化内容

client.chat.completions.create(
    model=model,
    response_model=StructuredDocument,
    max_tokens=4000,
    temperature=0.0,
    messages=[
        {
            "role": "system",
            "content": system_prompt.format(start_line=start_line, end_line=end_line),
        },
        {
            "role": "user",
            "content": document_with_line_numbers,
        },
    ],
)
```

可以看到就是一个简单的 ChatGPT 调用，就根据文本生成结构化的结果。后续根据分片的 `start_index` 和 `end_index` 确定分片的开始和结尾内容，从而实现了语义分片。

#### 自动上下文

自动上下文主要期望解决原始文本不容易检索的问题，实际在生产环境应用过 RAG 服务就很容易发现，原始文档中总是会存在部分内容不太容易检索。

比如以一个疾病的论文为例，可能会存在一段介绍疾病对应的治疗方案，但是治疗方案的内容中可能没有相关疾病的描述，如果检索相关病例的治疗手段，可能会发现没办法检索到相关的治疗方案。

dsRAG 补充的上下文信息目前支持文档标题，文档摘要，文档块的标题，文档块的摘要。这些内容从何而来呢？答案与上面的分片一样：大模型。

dsRAG 为上面的四种类型的数据分别实现一个对应的 prompt，之后就可以借助大模型实现对应的功能了，举例来看，实现文档标题的对应的 prompt 如下所示：

```python
DOCUMENT_TITLE_PROMPT = """
INSTRUCTIONS
What is the title of the following document?

Your response MUST be the title of the document, and nothing else. DO NOT respond with anything else.

{document_title_guidance}

{truncation_message}

DOCUMENT
{document_text}
""".strip()
```

生成对应的上下文数据之后，将上下文与分片的内容组合在一起进行了向量化，这样就得到了更容易检索的文本块了。

#### 文本块智能组合

文本智能组合（Relevant Segment Extraction, RSE）是将检索到的文本块进行聚类，并进行智能组合形成更长的文本。通过类似的方案，dsRAG 在回答复杂问题，特别是需要跨越多个文本的问题时就具备明显优势。

根据官方给出的测试数据来看，RSE 是对效果影响最大的策略，官方测试评分如下所示：

| | Top-k| RSE | CCH+Top-k | CCH+RSE |
|---|---|---|---|---|
|AI Papers | 4.5 | 7.9 | 4.7 | 7.9 |
| BVP Cloud | 2.6 | 4.4 | 6.3 | 7.8 |
| Sourcegraph | 5.7 | 6.6 | 5.8 | 9.4 |
| Supreme Court Opinions | 6.1 | 8.0 | 7.4 | 8.5 |
| Average | 4.72 | 6.73 | 6.04 | 8.42 |

通过单纯的文本块智能组合策略就可以取得不错的分数，当然结合了自动上下文（CCH） + 文本块智能组合（RSE） 肯定是最好的。


