---
layout: post
title: "来自工业界的开源知识库 RAG 项目最全细节对比"
subtitle:   "The most complete comparison of open source RAG projects from the industry"
date:       2024-07-08 22:00:00
author:     "Bryan"
header-mask: 0.3
catalog:    true
tags:
    - python
    - rag
    - agent
---

## 背景介绍
之前从原理到实现细节整理过来自工业界的不少开源 RAG 项目：

- [有道 QAnything](https://zhuanlan.zhihu.com/p/697031773)
- [RAGFlow](https://zhuanlan.zhihu.com/p/697902937)
- [langchain-chatchat](https://zhuanlan.zhihu.com/p/689947142)
- [中科院 GoMate](https://zhuanlan.zhihu.com/p/705218535)
- [Dify](https://zhuanlan.zhihu.com/p/706381113)
- [FastGPT](https://zhuanlan.zhihu.com/p/707152910)

群里有小伙伴询问在实际的业务需求中如何选择合适的 RAG 项目，本文就详细对比一下这些项目，考虑到目前实际发展程度，GoMate 目前的可靠性还不适合在生产环境使用。因此主要对比其他几个更成熟的热门开源项目。

如果只关心技术选项方案，可以直接看文末的总结。

## 项目基础信息介绍
主要关注项目的一些基础信息，可以给出初步选型比较：

| 项目 |  Star 数量 | 持续维护性 | 社区活跃度 | 代码质量 | 版权信息 |
| --- |  --- | --- | --- | --- | --- |
| [QAnything](https://github.com/netease-youdao/QAnything) | 10.6k | ⭐️ | ⭐️⭐️ | ⭐️⭐️⭐️ | Apache-2.0 |
| [RAGFlow](https://github.com/infiniflow/ragflow) | 11.2k | ⭐️⭐️⭐️ | ⭐️⭐️⭐️ | ⭐️⭐️ | Apache-2.0 |
| [langchain-chatchat](https://github.com/chatchat-space/Langchain-Chatchat) | 29.7k | ⭐️⭐️⭐️ | ⭐️⭐⭐️ | ⭐️⭐️ | Apache-2.0 |
| [Dify](https://github.com/langgenius/dify) | 36.7k | ⭐️⭐️⭐️ | ⭐️⭐️⭐️ | ⭐️⭐️⭐️ | 附加条件的 Apache-2.0 |
| [FastGPT](https://github.com/labring/FastGPT) | 15.3k | ⭐️⭐️⭐️ | ⭐️⭐️⭐️ | ⭐️⭐️ | 附加条件的 Apache-2.0 |

- 项目热度上，Dify 和 langchain-chatchat 因为开源较早，star 数量最多，其他项目也属于比较热的了；
- 项目可维护性上，除了 QAnything 之外的其他项目都在持续更新，QAnything 反馈 5-17 后就不会再新增新功能了，因此建议谨慎选择；
- 代码质量上，QAnything 和 Dify 质量较高；
- 版权问题上，Dify 和 FastGPT 限制不允许用于构建多租户的 Saas 服务，不允许去掉版权信息，其他的都没有限制；

考虑到项目开箱即用的程度以及二次开发的难度，下面主要对比下技术栈：

| 项目 | 前端技术栈 | 后端技术栈 |
| --- |  --- | --- |
| QAnything | 只有打包后前端文件，无法二次开发 | python + sanic |
| RAGFlow | React + TypeScript | python + flask |
| langchain-chatchat | Streamlit 实现的临时前端 | python + FastAPI |
| Dify | NextJs + TypeScript | python + flask |
| FastGPT | NextJs + TypeScript | NextJs + TypeScript |

- 从前端角度来看，langchain-chatchat 没有生产环境可用的前端，QAnything 无法提供可修改的前端，其他几家都有可用的前端页面，技术栈都是基于 React 的
- 从后端角度来看，除了 FastGPT 选择了基于 TypeScript 构建，其他都是基于 Python 开发的；


## 项目框架对比
主要比较不同项目的核心亮点，方便有针对性选择合适的项目

**QAnything**

![qanything](/img/in-post/compare/qanything_arch.png)

- 重点强调 Rerank 机制，强调 Embedding + Rerank 模型的联合使用可以提升文档召回质量；

**RAGFlow**

![ragflow](/img/in-post/compare/ragflow-arch.png)

- 重点强调文档的精细化解析，在文档解析上做了不少优化；

**langchain-chatchat**

![langchain-chatchat](/img/in-post/compare/langchain-chatchat.png)

- 强调支持离线私有化部署，对于私有化部署支持完善

**Dify**

![dify](/img/in-post/compare/dify.png)

- 丰富的召回模式，支持跨知识库召回；
- 支持 QA 模式，可以基于原始文档生成问答对进行召回；
- 支持工作流编排；

**FastGPT**

![fastgpt](/img/in-post/compare/fastgpt.webp)

- 支持 QA 模式，可以基于原始文档生成问答对进行召回；
- 支持工作流编排；

总结而言，如果对于文件精细解析感兴趣，可以优先选择 RAGFlow。如果重点关注离线部署，可以看看 langchain-chatchat。如果希望具备任务流编排或 Agent 相关能力，可以关注 Dify 和 FastGPT


## RAG 能力比较
作为 RAG 服务，从我目前了解的信息来看，主要关注下面的一些基础能力：

1. 文件的精细解析能力，是否能支持常规格式，是否具备结构化分片与检索的能力；
2. 知识库检索效果，因为知识库检索是 RAG 的核心能力，能否高质量召回直接决定 RAG 的最终表现；
3. 跨知识库检索的支持，目前来看跨知识库检索，自动选择合适的知识库对上层业务还是比较友好的，也是比较实用的能力；

下面从这些角度比较现有项目, 注意比较存在一些主观因素，同时各个项目也在持续迭代，后续项目中缺失的能力也可能会被补齐，所以大家可以参考下，实际使用时还需要自行调研下：

| 项目 |  文件精细解析能力 | 知识库检索效果 | 跨知识库检索支持 |
| --- |  --- | --- | --- |
| QAnything | ⭐️⭐️ | ⭐️⭐️ | ⭐️ |
| RAGFlow | ⭐️⭐️ | ⭐️⭐️ | ⭐️ |
| langchain-chatchat | ⭐️⭐️ | ⭐️⭐️ | ⭐️ |
| Dify | ⭐️⭐️ | ⭐️ | ⭐️⭐️⭐️ |
| FastGPT | ⭐️ | ⭐️⭐️ | ⭐️ |

- 文件精细解析，RagFlow 应该做的最深入的，但是实际测试解析很慢，而且容易失败，所以没有额外给更高的评分。FastGPT 目前支持的格式会更少一些，部分原因是因为 js 没有 Python 那么丰富的库可以使用；
- 知识库检索，实际测试时常规几个的检索效果都还不错，但是 Dify 测试时检索效果不佳，经常召回不到正确的内容；
- 跨知识库检索，目前只有 Dify 提供了相关的能力，而且支持的模式比较丰富，其他的应该都还没有支持；


## Agent 能力比较

目前实际在生产环境使用时，除了单纯的知识库检索之外，可能会需要拓展其他外部工具，并根据业务流程实际情况编排现有的组合，因此主要关注下面两部分能力：

- 能否拓展支持其他工具；
- 能否支持任务流编排；

下面主要从这些部分比较现有项目：

| 项目 | 工具可拓展性 | 支持任务流编排 |
| --- |  --- | --- |
| QAnything | ⭐️ | ⭐️ |
| RAGFlow | ⭐️ | ⭐️⭐️ |
| langchain-chatchat | ⭐️ | ⭐️ |
| Dify | ⭐️⭐️⭐️ | ⭐️⭐️⭐️ |
| FastGPT | ⭐️⭐️ | ⭐️⭐️⭐️ |

- 工具可拓展性上，Dify 目前比较完善，支持了大量的外部拓展工具，新工具的支持也更便利，FastGPT 同样也具备良好的拓展性，其他项目主打 RAG 方向，在这一块的支持比较有限；
- 任务流编排，目前 Dify 和 FastGPT 都支持良好，RAGFlow 刚刚上线，其他都还没有支持；


## 项目部署比较
RAG 涉及的不同的服务以及模型的部署，选择 RAG 方案的企业很多都关心内部内容的隐私问题，一般期望能私有化部署。目前主要从这两方面比较下现有项目：

1. 部署难易程度；
2. 是否支持离线部署；

| 项目 | 部署难易程度 | 是否支持离线部署 |
| --- |  --- | --- |
| QAnything | ⭐️⭐️ | ⭐️⭐️ |
| RAGFlow | ⭐️⭐️ | ⭐️⭐️ |
| langchain-chatchat | ⭐️⭐️ | ⭐️⭐️ |
| Dify | ⭐️⭐️ | ⭐️⭐️ |
| FastGPT | ⭐️⭐️ | ⭐️⭐️ |

从目前来看，项目部署都是基于 docker 进行部署，如果需要在离线环境部署，需要下载准备 docker 镜像。部分项目提供了源码安装的方式，但是操作会繁琐很多，建议还是优先选择 docker 方案。

## 总结

本文对比了目前比较热门的 RAG 项目，给出一些推荐建议：

- 综合评价最完备的应该是 Dify，功能比较完善，而且可拓展性较好，但是需要注意版权问题，另外 RAG 检索效果不佳的问题需要进行一些优化；
- 如果不熟悉 Python 技术栈，希望尽可能专注业务功能的开发，那么可以优先选择 FastGPT；
- 如果对高质量的文件解析比较在意，可以参考 RAGFlow；
- 如果希望不借助 docker 快速搭建离线的 RAG 演示 demo，那么可以考虑 langchain-chatchat 0.2.x, langchain chatchat 0.3.0 以后也将模型部署迁移出去，相关设计也与其他方案差异不大了。



