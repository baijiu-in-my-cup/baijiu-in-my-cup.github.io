---
layout: post
title: "来自工业界的知识库 RAG 服务(三)，FinGLM 竞赛获奖项目详解"
subtitle:   "Knowledge base RAG service from the industry (3), detailed explanation of the winning projects of the FinGLM competition"
date:       2024-06-05 21:00:00
author:     "Bryan"
header-mask: 0.3
catalog:    true
tags:
    - python
    - rag
    - langchain
---

## 背景介绍

前面介绍过工业界的 RAG 服务 [QAnything ](https://zhuanlan.zhihu.com/p/697031773) 和 [RagFlow](https://zhuanlan.zhihu.com/p/697902937) 的详细设计，也介绍过来自学术界的 [一些优化手段](https://zhuanlan.zhihu.com/p/700338148)。

前一阵子刚好看到智谱组织的一个金融大模型比赛 [FinGLM](https://github.com/MetaGLM/FinGLM)，主要做就是 RAG 服务的竞赛，深入研究了其中的几个获奖作品，得到了不少启发。整理一些获奖项目的设计方案，希望也帮助大家加速研究过程。

## 获奖项目介绍

在天池的 [决赛文章](https://tianchi.aliyun.com/forum/post/597108) 可以看到最终获奖的队伍，本文主要想介绍的是项目是决赛获得第三名的 “ChatGLM反卷总局” 团队的项目，为什么没有选择前面的团队的项目，主要原因是：“ChatGLM反卷总局” 是获奖作品中性价比极高的实现方案：

1. 其他团队或多或少都做了模型的微调，甚至获得第一名团队微调了 2 到 3 个模型，“ChatGLM反卷总局” 没有做任何的微调就取得了不错的成绩；
2. 在原始 chatGLM 做关键词提取效果很差的情况下，其他团队只能靠微调解决，“ChatGLM反卷总局” 基于原始模型 + 正则表达式就实现了不错的效果；
3. 实现方案比较轻量，没有引入太多额外服务，生产环境可以方便应用；

## FinGLM 比赛介绍

[FinGLM](https://github.com/MetaGLM/FinGLM) 是基于固定数量的上市公司财报文档构建知识库，并固定使用 ChatGLM-6B 作为大模型完成知识库问答。回答的问题包含三类：

1. 初级问题，可以直接从原文中获得信息进行回答，比如直接问特定公司某一年的研发费用，考察的是能否正确检索到内容的能力；
2. 中级问题，需要对原文中内容进行统计分析和关联，比如问某公司某一年研发费用的增长率，考虑的是能否检索到内容并进行二次加工得到结果的能力；
3. 高级问题，安全开放的问题，比如问研发项目是否涉及国家战略，考察的是检索到内容并综合处理的能力；

可以看到使用一个相对小的大模型，需要能准确回答上面的这些问题，对于内容的检索以及架构精细设计要求还是很高的，直接使用 [最原始的 RAG 框架](https://zhuanlan.zhihu.com/p/689947142) 肯定是不够的, 发挥不稳定的向量检索大概率是无法帮你获奖的。

#### 比赛难点
根据我研究的答辩过程中的一些共同的反馈，整理此比赛中的一些难点：

1. 财报中包含大量的数据，掺杂文本内容与表格数据，很多精细的问题都需要依赖表格进行回答，如何进行精细的处理原始文档中的内容可以被正确检索到；
2. 不同类型的问题需要不同的处理方案，如何区分不同的问题进行有针对性的方案解决；
3. ChatGLM-6B 模型较弱，稍微复杂的情况就无法正确处理，甚至模型的输出就不可控了，如果保证稳定输出正确的答案；
4. 用户问题与原始文档关键字存在差异，如果保证能正确检索到完全准确的内容；








