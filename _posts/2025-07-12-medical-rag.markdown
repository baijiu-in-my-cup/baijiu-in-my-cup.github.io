---
layout: post
title: "大模型应用落地反思：突破RAG幻想，以场景为锚，用评估导航"
subtitle:   "Reflections on the application of LLM: Break through RAG fantasy, anchor with scenarios, and navigate with evaluation"
date:       2025-07-12 12:00:00
author:     "Bryan"
header-mask: 0.3
catalog:    true
tags:
    - rag
    - llm
---

## 背景介绍

在过去几年，针对医疗场景做了不少大模型应用落地的尝试，不知不觉间[大模型技术专栏](https://www.zhihu.com/column/c_1709670747138748418)也积累了接近 60 篇技术博客了。在实践过程中尝试技术栈包括 RAG，Agent，模型微调，知识图谱等，在一些医学通用场景的 RAG 的准确性也从最初的 50% 提升至 90%。但是在医学这种严肃的应用场景下，在实际应用中依旧还不能完全满足生产需要，需要进一步提升遇到的不少的新挑战。

在 2025 年以来，进一步深入到医学具体场景下，做了不少不那么通用 AI 的方案尝试，部分方案反而取得了良好的效果，在特定场景下真正能满足生产需求。一路探索下来，有一些大模型应用落地的心得体会，在这边抛砖引玉分享一下。

## 通用方案的局限性
在过去的 2024 年 RAG 大模型应用领域落地的最热门的方向，在 2025 年以来热度有明显的下降，就像 [2025 RAG技术现状盘点](https://mp.weixin.qq.com/s/C1E4hdhaaVf7GCbnonoZhw) 中描述的那样，2025 年上半年以来鲜少出现新的技术突破了，RAG 的技术方向进入了瓶颈期。而从过去的实践来看，期待一个相对简单的通用大模型技术方案能解决现实中的多种多样的问题基本上是不现实的。目前的各个大模型场景或多或少都有明显的局限性。

比如通用的 RAG 服务应用在医疗领域，实践中会发现如下所示的问题：

1. **向量检索的精度问题**：医学知识并不是堆砌概念的向量空间。一次 CT 检查是否做了增强、一个肝脏病灶是否超过 3cm、糖尿病并发症是否已影响视网膜……这些“细节”极其关键，却往往在语义近似的向量空间中被稀释甚至忽略。向量检索的最大问题在于“模糊性”，而医学问题恰恰是需要“精确性”的代表。两个病例也许主诉，现病史非常相似，但一个做了肿瘤标志物检查，一个没有；一个患者有抗药史，一个没有。这些微小但关键的差异决定了诊断与用药方向的关键差异，而向量模型很难做出有效区分；
2. **分片检索的信息完整性问题**：为了适应模型的上下文窗口限制，RAG 方案通常将长文档分片后向量化处理。然而，这种分片策略在医学场景中常常导致信息割裂。例如，一份完整的病历可能包含患者病史、检查结果和医嘱等多部分内容，分片后的检索可能只返回部分片段，丢失了上下文的完整性。在处理长篇医学文献时，不完整的医疗信息基本无法支持可靠的医学推导；
3. **应用场景的多样性**：在实际的现实世界中，用户的需求是多样性而不统一的。期望借助一个通用的知识增强去解决通用的请求，就会发现大量的长尾问题。从而导致通用方案上需要增加大量的`雕花`技巧，而过多技巧的叠加会带来系统的复杂性维护与处理效率问题；

## 场景化的解决方案

我们逐渐意识到：通用方案无法覆盖现实医疗的复杂性。只有将技术落入实际场景，重新理解业务流程，才能设计出真正可行的解决方案。下面以一个具体的例子进行具体解释：

在医疗场景下，直接使用预训练大模型往往不足的，因为大模型往往会存在幻觉，相关的医学知识不足，时效性也存在明显问题。需要后置的医学知识进行增强。

RAG 就是目前各家公司采用最多的方案，但是在实践 RAG 之后，相信不久大家就会发现一些明显的局限性，于是就会应用多种多样的优化手段，常规的优化手段在 [RAG 最佳实践](https://zhuanlan.zhihu.com/p/8861103446) 和 [RAG 最佳实践 2025 补充](https://zhuanlan.zhihu.com/p/1924463502703167032) 中都进行了介绍，有兴趣的可以深入了解。在这个 RAG 的不断迭代中，持续会发现的新的长尾问题，而且准确性达到 90% 以后，进一步的提升就十分困难了。

我们在实际中也经历过类似的迭代循环，但是在实际的应用场景定义后，我们实际发现，在我们设计的医学应用场景中，应用场景中都是包含明确的病例诊断的。而大量的医学指南知识都是以疾病为单位进行整理的。实际的医学知识匹配往往可以借助明确的疾病名称进行进一步的精确匹配，从而避免向量检索的模糊性导致的明显不准确的问题。当然实际医学场景中直接使用疾病名称也会存在别名导致的不准确，此时再进一步，借助医学的 [ICD 编码](https://code.nhsa.gov.cn/search.html?sysflag=80) 就可以进一步解决这个问题。此时解决方案演变如下所示：

![match](/img/in-post/medical-rag/match.png)

通过这样的方案，才能真正解决疾病知识场景下的匹配准确性问题。通过这种方案，准确性才能跨越从 90% 至 100% 的鸿沟。当然这只是医疗场景下的一个典型例子，实际的应用需要根据具体的业务属性挖掘出匹配的解决方案。

## 数据飞轮驱动下的技术迭代

大模型应用的落地不仅需要合适的技术方案，还需要一个完善的评估体系来支撑业务流程的持续迭代。没有清晰的评估体系，项目往往会陷入“什么都想做，却什么都做不好”的困境。而且大模型应用往往都是大量的文字输出，如果没有明确的评估机制，很难确定技术迭代的可靠性。

这个想法在大模型时代其实比较常见了，针对不同的应用场景大家往往会建立对应的 BenchMark 进行批量测试。比如针对向量模型存在有名的 [mteb](https://huggingface.co/spaces/mteb/leaderboard) 榜单，而大模型的榜单就更多的了，比如 [lmarena](https://lmarena.ai/leaderboard) 等。

以我的实践经验来看，大部分的通用榜单数据集都很难直接提供给应用进行使用，最合适的方案是根据自己的业务场景定义自己的评估数据集。基于真正匹配业务目标的数据集引导应用的迭代方向，因此我认为大模型应用的合适技术迭代流程如下所示：

![loop](/img/in-post/medical-rag/loop.png)

## 总结

本文是根据过去的医学大模型应用落地过程的一些实践产生的一些想法，纯属一家之言。虽然我提到了不少通用 RAG 的局限性，但是我依旧相信 RAG 是一个十分不错的技术方案，在需要进行知识检索上能发挥一些明显的作用。但是更重要的是明确自己构建的大模型应用的具体应用场景，针对具体的应用场景构建真正适配的解决方案，并基于数据飞轮进行持续迭代优化，这样才能真正构建可以落地的大模型产品。
